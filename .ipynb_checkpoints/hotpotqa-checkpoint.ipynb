{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import openai\n",
    " \n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# def llm(prompt, stop=[\"\\n\"]):\n",
    "#     response = openai.Completion.create(\n",
    "#       model=\"text-davinci-002\",\n",
    "#       prompt=prompt,\n",
    "#       temperature=0,\n",
    "#       max_tokens=100,\n",
    "#       top_p=1,\n",
    "#       frequency_penalty=0.0,\n",
    "#       presence_penalty=0.0,\n",
    "#       stop=stop\n",
    "#     )\n",
    "#     return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    contents=\"Explain how AI works in a few words\", \n",
    "    config=types.GenerateContentConfig(\n",
    "        top_p=1.0,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make intelligent decisions or predictions.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)  # Print the first candidate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "folder = './prompts/'\n",
    "prompt_file = 'prompts_naive.json'\n",
    "with open(folder + prompt_file, 'r') as f:\n",
    "    prompt_dict = json.load(f)\n",
    "\n",
    "webthink_examples = prompt_dict['webthink_simple6']\n",
    "instruction = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: \n",
    "(1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "(2) Lookup[keyword], which returns the next sentence containing keyword in the current passage.\n",
    "(3) Finish[answer], which returns the answer and finishes the task.\n",
    "\n",
    "IMPORTANT: (1) always return you thought if there is any; (2) returns only one step at a time.\n",
    "\n",
    "Here are some examples.\n",
    "\"\"\"\n",
    "webthink_prompt = instruction + webthink_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, stop=[\"\\n\"]):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=webthink_prompt,\n",
    "            top_p=1.0,\n",
    "            temperature=0.0,  # Lower temperature for more deterministic output\n",
    "            max_output_tokens=100,  # Limit the output length\n",
    "            stop_sequences=stop,  # Stop sequences to end generation\n",
    "            \n",
    "        ),\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are Freakonomics and In the Realm of the Hackers both American documentaries?\n"
     ]
    }
   ],
   "source": [
    "question = env.reset(idx=33)\n",
    "print(question)\n",
    "n_calls, n_badcalls = 0, 0\n",
    "\n",
    "prompt = question + \"\\n\"\n",
    "action = llm(prompt)\n",
    "action = action.split(f\"Action {1}: \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 1: Search[Freakonomics]\n",
      "Search[Freakonomics]\n"
     ]
    }
   ],
   "source": [
    "print(action)\n",
    "print(action.split(f\"Action {1}: \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_input: search[Freakonomics]\n",
      "Freakonomics: A Rogue Economist Explores the Hidden Side of Everything is the debut non-fiction book by University of Chicago economist Steven Levitt and New York Times journalist Stephen J. Dubner. Published on April 12, 2005, by William Morrow, the book has been described as melding pop culture with economics.[1] By late 2009, the book had sold over 4 million copies worldwide.[2]  Based on the success of the original book, Levitt and Dubner have grown the Freakonomics brand into a multi-media franchise, with a sequel book, a feature film, a regular radio segment on National Public Radio, and a weekly blog.. The book is a collection of articles written by Levitt, an economist who had gained a reputation for applying economic theory to diverse subjects not usually covered by \"traditional\" economists. In Freakonomics, Levitt and Dubner argue that economics is, at root, the study of incentives.\n",
      "0\n",
      "False\n",
      "{'steps': 1, 'answer': None}\n"
     ]
    }
   ],
   "source": [
    "step_input = action[0].lower() + action[1:]\n",
    "print(f'step_input: {step_input}')\n",
    "obs, r, done, info = step(env, step_input)\n",
    "print(obs)\n",
    "print(r)\n",
    "print(done)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are Freakonomics and In the Realm of the Hackers both American documentaries?\n",
      "Action 1: Search[Freakonomics]\n",
      "Observation 3687: Freakonomics: A Rogue Economist Explores the Hidden Side of Everything is the debut non-fiction book by University of Chicago economist Steven Levitt and New York Times journalist Stephen J. Dubner. Published on April 12, 2005, by William Morrow, the book has been described as melding pop culture with economics.[1] By late 2009, the book had sold over 4 million copies worldwide.[2]  Based on the success of the original book, Levitt and Dubner have grown the Freakonomics brand into a multi-media franchise, with a sequel book, a feature film, a regular radio segment on National Public Radio, and a weekly blog.. The book is a collection of articles written by Levitt, an economist who had gained a reputation for applying economic theory to diverse subjects not usually covered by \"traditional\" economists. In Freakonomics, Levitt and Dubner argue that economics is, at root, the study of incentives.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step_str = f\"Action {1}: {action}\\nObservation {i}: {obs}\\n\"\n",
    "prompt += step_str\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1: The question asks if \"Freakonomics\" and \"In the Realm of the Hackers\" are both American documentaries. I have searched \"Freakonomics\" and the result mentions a \"feature film\" based on the book, but it doesn't explicitly state if it's a documentary or its country of origin. I need to investigate the film further.\n"
     ]
    }
   ],
   "source": [
    "thought = llm(prompt)\n",
    "print(thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt += thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are Freakonomics and In the Realm of the Hackers both American documentaries?\n",
      "Action 1: Search[Freakonomics]\n",
      "Observation 3687: Freakonomics: A Rogue Economist Explores the Hidden Side of Everything is the debut non-fiction book by University of Chicago economist Steven Levitt and New York Times journalist Stephen J. Dubner. Published on April 12, 2005, by William Morrow, the book has been described as melding pop culture with economics.[1] By late 2009, the book had sold over 4 million copies worldwide.[2]  Based on the success of the original book, Levitt and Dubner have grown the Freakonomics brand into a multi-media franchise, with a sequel book, a feature film, a regular radio segment on National Public Radio, and a weekly blog.. The book is a collection of articles written by Levitt, an economist who had gained a reputation for applying economic theory to diverse subjects not usually covered by \"traditional\" economists. In Freakonomics, Levitt and Dubner argue that economics is, at root, the study of incentives.\n",
      "Thought 1: The question asks if \"Freakonomics\" and \"In the Realm of the Hackers\" are both American documentaries. I have searched \"Freakonomics\" and the result mentions a \"feature film\" based on the book, but it doesn't explicitly state if it's a documentary or its country of origin. I need to investigate the film further.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action 2: Search[Freakonomics (film)]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webthink2(idx=None, prompt='', to_print=True):\n",
    "    question = env.reset(idx=idx)\n",
    "    if to_print:\n",
    "        print(idx, question)\n",
    "    prompt += question + \"\\n\"\n",
    "    n_calls, n_badcalls = 0, 0\n",
    "    for i in range(1, 8):\n",
    "        n_calls +=1\n",
    "        llm_result = llm(prompt)\n",
    "        print(llm_result)\n",
    "        prompt += llm_result + '\\n'\n",
    "        if (llm_result.startswith('Thought')):\n",
    "            continue\n",
    "        elif (llm_result.startswith('Action')):\n",
    "            delimiter_pattern = r\"Action \\d+: \"\n",
    "            action = re.split(delimiter_pattern, llm_result)\n",
    "            step_input = action[0].lower() + action[1:]\n",
    "            print(f'step_input: {step_input}')\n",
    "            obs, r, done, info = step(env, step_input)\n",
    "\n",
    "            prompt += llm_result\n",
    "        else:\n",
    "            print(f'I don\\'t understand this:\\n {llm_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Question: Which band, Letters to Cleo or Screaming Trees, had more members?\n",
      "Action 1: Search[Letters to Cleo]\n",
      "Action 1: Search[Letters to Cleo]\n",
      "Action 1: Search[Letters to Cleo]\n",
      "Action 1: Search[Letters to Cleo]\n",
      "Action 1: Search[Letters to Cleo]\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m webthink2(\u001b[32m34\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mwebthink2\u001b[39m\u001b[34m(idx, prompt, to_print)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m8\u001b[39m):\n\u001b[32m      8\u001b[39m     n_calls +=\u001b[32m1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     llm_result = llm(prompt)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(llm_result)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (llm_result.startswith(\u001b[33m'\u001b[39m\u001b[33mThought\u001b[39m\u001b[33m'\u001b[39m)):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mllm\u001b[39m\u001b[34m(prompt, stop)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm\u001b[39m(prompt, stop=[\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m]):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     response = client.models.generate_content(\n\u001b[32m      3\u001b[39m         model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m         contents=prompt,\n\u001b[32m      5\u001b[39m         config=types.GenerateContentConfig(\n\u001b[32m      6\u001b[39m             system_instruction=webthink_prompt,\n\u001b[32m      7\u001b[39m             top_p=\u001b[32m1.0\u001b[39m,\n\u001b[32m      8\u001b[39m             temperature=\u001b[32m0.0\u001b[39m,  \u001b[38;5;66;03m# Lower temperature for more deterministic output\u001b[39;00m\n\u001b[32m      9\u001b[39m             max_output_tokens=\u001b[32m100\u001b[39m,  \u001b[38;5;66;03m# Limit the output length\u001b[39;00m\n\u001b[32m     10\u001b[39m             stop_sequences=stop,  \u001b[38;5;66;03m# Stop sequences to end generation\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m         ),\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/google/genai/models.py:5898\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5896\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5897\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5898\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   5899\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   5900\u001b[39m   )\n\u001b[32m   5901\u001b[39m   logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is done.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   5902\u001b[39m   remaining_remote_calls_afc -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/google/genai/models.py:4838\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4835\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   4836\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4838\u001b[39m response = \u001b[38;5;28mself\u001b[39m._api_client.request(\n\u001b[32m   4839\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   4840\u001b[39m )\n\u001b[32m   4842\u001b[39m response_dict = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.body \u001b[38;5;28;01melse\u001b[39;00m json.loads(response.body)\n\u001b[32m   4844\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/google/genai/_api_client.py:1067\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1059\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1062\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1063\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1064\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1065\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1066\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1067\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._request(http_request, stream=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1068\u001b[39m   response_body = (\n\u001b[32m   1069\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1070\u001b[39m   )\n\u001b[32m   1071\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/google/genai/_api_client.py:958\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request\u001b[39m(\n\u001b[32m    954\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    955\u001b[39m     http_request: HttpRequest,\n\u001b[32m    956\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    957\u001b[39m ) -> HttpResponse:\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = action(retry_state)\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    416\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc.reraise()\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.result()\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = fn(*args, **kwargs)\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/google/genai/_api_client.py:948\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    941\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m    942\u001b[39m       method=http_request.method,\n\u001b[32m    943\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    946\u001b[39m       timeout=http_request.timeout,\n\u001b[32m    947\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m   errors.APIError.raise_for_response(response)\n\u001b[32m    949\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    950\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    951\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/llm/lib/python3.11/site-packages/google/genai/errors.py:104\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    102\u001b[39m status_code = response.status_code\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    106\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}"
     ]
    }
   ],
   "source": [
    "webthink2(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Action 1: Search[Freakonomics]' split: ['', 'Search[Freakonomics]']\n",
      "'Action 123: Lookup[keyword]' split: ['', 'Lookup[keyword]']\n",
      "'Action 5: Finish[answer]' split: ['', 'Finish[answer]']\n",
      "'Some preamble. Action 7: Another action.' split: ['Some preamble. ', 'Another action.']\n",
      "'Just a regular sentence.' split: ['Just a regular sentence.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example strings with different numbers\n",
    "text1 = 'Action 1: Search[Freakonomics]'\n",
    "text2 = 'Action 123: Lookup[keyword]'\n",
    "text3 = 'Action 5: Finish[answer]'\n",
    "\n",
    "# The regular expression pattern for the delimiter:\n",
    "# r\"Action \\d+: \"\n",
    "#   - r\"\"       : Denotes a raw string, good for regex to avoid backslash issues.\n",
    "#   - \"Action \" : Matches the literal string \"Action \"\n",
    "#   - \\d+       : Matches one or more digits (this handles any number 'n')\n",
    "#   - \": \"      : Matches the literal string \": \"\n",
    "delimiter_pattern = r\"Action \\d+: \"\n",
    "\n",
    "# Split text1\n",
    "result1 = re.split(delimiter_pattern, text1)\n",
    "print(f\"'{text1}' split: {result1}\")\n",
    "\n",
    "# Split text2\n",
    "result2 = re.split(delimiter_pattern, text2)\n",
    "print(f\"'{text2}' split: {result2}\")\n",
    "\n",
    "# Split text3\n",
    "result3 = re.split(delimiter_pattern, text3)\n",
    "print(f\"'{text3}' split: {result3}\")\n",
    "\n",
    "# Example where the pattern might not be at the very beginning\n",
    "text4 = 'Some preamble. Action 7: Another action.'\n",
    "result4 = re.split(delimiter_pattern, text4)\n",
    "print(f\"'{text4}' split: {result4}\")\n",
    "\n",
    "# Example where the pattern is not found\n",
    "text5 = 'Just a regular sentence.'\n",
    "result5 = re.split(delimiter_pattern, text5)\n",
    "print(f\"'{text5}' split: {result5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "folder = './prompts/'\n",
    "prompt_file = 'prompts_naive.json'\n",
    "with open(folder + prompt_file, 'r') as f:\n",
    "    prompt_dict = json.load(f)\n",
    "\n",
    "webthink_examples = prompt_dict['webthink_simple6']\n",
    "instruction = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: \n",
    "(1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "(2) Lookup[keyword], which returns the next sentence containing keyword in the current passage.\n",
    "(3) Finish[answer], which returns the answer and finishes the task.\n",
    "\n",
    "IMPORTANT: returns only one step at a time.\n",
    "\n",
    "Here are some examples.\n",
    "\"\"\"\n",
    "webthink_prompt = instruction + webthink_examples\n",
    "\n",
    "def webthink(idx=None, prompt=webthink_prompt, to_print=True):\n",
    "    question = env.reset(idx=idx)\n",
    "    if to_print:\n",
    "        print(idx, question)\n",
    "    prompt += question + \"\\n\"\n",
    "    n_calls, n_badcalls = 0, 0\n",
    "    for i in range(1, 8):\n",
    "        n_calls += 1\n",
    "        # thought_action = llm(prompt + f\"Thought {i}:\", stop=[f\"\\nObservation {i}:\"])\n",
    "        thought_action = llm(prompt + f\"Thought {i}:\", stop=[f\"\\nObservation {i}:\"])\n",
    "        print(f'llm returned: {thought_action}')\n",
    "        try:\n",
    "            thought, action = thought_action.strip().split(f\"\\nAction {i}: \")\n",
    "        except:\n",
    "            print('ohh...', thought_action)\n",
    "            n_badcalls += 1\n",
    "            n_calls += 1\n",
    "            thought = thought_action.strip().split('\\n')[0]\n",
    "            action = llm(prompt + f\"Thought {i}: {thought}\\nAction {i}:\", stop=[f\"\\n\"]).strip()\n",
    "        obs, r, done, info = step(env, action[0].lower() + action[1:])\n",
    "        obs = obs.replace('\\\\n', '')\n",
    "        step_str = f\"Thought {i}: {thought}\\nAction {i}: {action}\\nObservation {i}: {obs}\\n\"\n",
    "        prompt += step_str\n",
    "        if to_print:\n",
    "            print(step_str)\n",
    "        if done:\n",
    "            break\n",
    "    if not done:\n",
    "        obs, r, done, info = step(env, \"finish[]\")\n",
    "    if to_print:\n",
    "        print(info, '\\n')\n",
    "    info.update({'n_calls': n_calls, 'n_badcalls': n_badcalls, 'traj': prompt})\n",
    "    return r, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687 Question: What movie did actress Irene Jacob complete before the American action crime thriller film directed by Stuart Bird?\n",
      "llm returned: Action 1: Search[Stuart Bird]\n",
      "ohh... Action 1: Search[Stuart Bird]\n",
      "Thought 1: Action 1: Search[Stuart Bird]\n",
      "Action 1: Action 1: Search[Stuart Bird]\n",
      "Observation 1: Invalid action: action 1: Search[Stuart Bird]\n",
      "\n",
      "llm returned: Action 1: Search[Stuart\n",
      "ohh... Action 1: Search[Stuart\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mwebthink\u001b[39m\u001b[34m(idx, prompt, to_print)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     thought, action = thought_action.strip().split(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m old_time = time.time()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs[:k]:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     r, info = webthink(i, to_print=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m     rs.append(info[\u001b[33m'\u001b[39m\u001b[33mem\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     15\u001b[39m     infos.append(info)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mwebthink\u001b[39m\u001b[34m(idx, prompt, to_print)\u001b[39m\n\u001b[32m     33\u001b[39m     n_calls += \u001b[32m1\u001b[39m\n\u001b[32m     34\u001b[39m     thought = thought_action.strip().split(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     action = llm(prompt + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThought \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthought\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m, stop=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m]).strip()\n\u001b[32m     36\u001b[39m obs, r, done, info = step(env, action[\u001b[32m0\u001b[39m].lower() + action[\u001b[32m1\u001b[39m:])\n\u001b[32m     37\u001b[39m obs = obs.replace(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "idxs = list(range(7405))\n",
    "random.Random(233).shuffle(idxs)\n",
    "\n",
    "# k = 500  # Number of examples to run\n",
    "k = 5\n",
    "\n",
    "rs = []\n",
    "infos = []\n",
    "old_time = time.time()\n",
    "for i in idxs[:k]:\n",
    "    r, info = webthink2(i, to_print=True)\n",
    "    rs.append(info['em'])\n",
    "    infos.append(info)\n",
    "    print(sum(rs), len(rs), sum(rs) / len(rs), (time.time() - old_time) / len(rs))\n",
    "    print('-----------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action 1: Search[Stuart Bird]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Action 1: Search[Stuart Bird]'.strip().split(f\"\\nAction {i}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
